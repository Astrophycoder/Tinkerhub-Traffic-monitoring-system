# -*- coding: utf-8 -*-
"""trafficmodel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zEuQWZL6Uc7i7ZXKR9yedZdUvPIWQxPa

## Welcome!

Due to technical issues in the system and inability to install various packages in the system I used, the project is implemente in this file. Therefore please execute the cells below.

##User view
The code in the next two cells is user view. The heartbeat of the user is monitored using heartbeat detection apps which provide PPG(photoplethysmographic) which is connected to this application and anomal heartbeat is detected. Here a sample dataset is used.

A notification is sent to user asking "Are you in danger?" and when there is no response a signal is sent to the main system.
"""

# Install required packages
!pip install flask pyngrok ngrok pandas numpy scipy scikit-learn --quiet

# Import libraries
import pandas as pd
import numpy as np
from scipy.signal import butter, filtfilt, find_peaks
from scipy.fft import fft
from sklearn.ensemble import RandomForestClassifier
from flask import Flask, jsonify, request
import os
from datetime import datetime
from pyngrok import ngrok, conf
from threading import Thread
import time
import socket
import requests

!ngrok config add-authtoken 2s8oMYFwIfZtMZOCuhgBQVVA41j_3rvWEvpusuQ3LrMgSbght

# Clean up previous sessions and ports
ngrok.kill()  # Terminate all existing ngrok sessions
!pkill -f ngrok > /dev/null 2>&1  # Force-kill lingering processes
!fuser -k 5000/tcp > /dev/null 2>&1  # Clear default Flask port

# Dynamic port allocation
def find_free_port():
    """Find an available network port"""
    sock = socket.socket()
    sock.bind(('', 0))
    return sock.getsockname()[1]

# Ngrok configuration
NGROK_CONFIG = '''
version: "2"
authtoken: 2s8oMYFwIfZtMZOCuhgBQVVA41j_3rvWEvpusuQ3LrMgSbght
tunnels:
  flask-app:
    addr: {port}
    proto: http
    bind_tls: true
    host_header: "localhost"
'''

# Initialize Flask app
app = Flask(__name__)

# Server configuration
HOST = "0.0.0.0"
PORT = find_free_port()  # Dynamic port assignment
os.environ['FLASK_ENV'] = 'production'

# Data handling
DATA_FILE = 'abnormal_signals.csv'
if not os.path.exists(DATA_FILE):
    pd.DataFrame(columns=['user_id', 'timestamp', 'lat', 'lng']).to_csv(DATA_FILE, index=False)

# Signal processing
def preprocess_ppg(signal, fs=100):
    """Preprocess PPG signal using a bandpass filter."""
    nyquist = 0.5 * fs
    b, a = butter(3, [0.5/nyquist, 5/nyquist], btype='band')
    return filtfilt(b, a, signal)

def extract_features(signal, fs):
    """Extract features from the PPG signal."""
    peaks, _ = find_peaks(signal, height=0.6*np.max(signal))
    return {
        'heart_rate': len(peaks) * (fs / len(signal)) * 60,
        'pulse_amp': np.ptp(signal),
        'dominant_freq': np.argmax(np.abs(fft(signal)))
    }

# Machine learning model
mi_classifier = RandomForestClassifier()
X_train = np.random.rand(100, 3)
y_train = np.random.randint(0, 2, 100)
mi_classifier.fit(X_train, y_train)

# Flask endpoints
@app.route('/')
def home():
    return jsonify({
        "status": "active",
        "endpoints": {
            "health_check": "/check_health (POST)"
        }
    })

@app.route('/check_health', methods=['POST'])
def health_check():
    try:
        if not request.is_json:
            return jsonify({"error": "Request must be JSON"}), 400

        data = request.json
        if 'user_id' not in data:
            return jsonify({"error": "Missing user_id"}), 400

        try:
            ppg_signal = pd.read_csv('/content/copyPPG_Dataset.csv').iloc[0].values
        except FileNotFoundError:
            ppg_signal = np.sin(2 * np.pi * 1 * np.linspace(0, 1, 1000))

        processed = preprocess_ppg(ppg_signal)
        features = extract_features(processed, 100)

        prediction = mi_classifier.predict(pd.DataFrame([features]))[0]

        if prediction == 1:
            if np.random.rand() > 0.5:
                log_abnormal_signal(data['user_id'])

        return jsonify({
            "status": "MI_risk" if prediction == 1 else "normal",
            "user_id": data['user_id'],
            "features": features
        })

    except Exception as e:
        return jsonify({"error": str(e)}), 500

def log_abnormal_signal(user_id):
    new_entry = pd.DataFrame([{
        'user_id': user_id,
        'timestamp': datetime.now().isoformat(),
        'lat': 51.505 + np.random.randn()*0.01,
        'lng': -0.09 + np.random.randn()*0.01
    }])
    new_entry.to_csv(DATA_FILE, mode='a', header=False, index=False)

!pip install pyngrok --upgrade

# Install required packages
!pip install flask pyngrok pandas numpy scipy scikit-learn --quiet

# Import libraries
import os
import socket
import time
import traceback
import numpy as np
import pandas as pd
import requests
from datetime import datetime
from threading import Thread
from scipy.signal import butter, filtfilt, find_peaks
from scipy.fft import fft
from sklearn.ensemble import RandomForestClassifier
from flask import Flask, jsonify, request
import ngrok

# Configuration Constants
HOST = "0.0.0.0"
DATA_FILE = 'abnormal_signals.csv'
NGROK_TOKEN = '2s8oMYFwIfZtMZOCuhgBQVVA41j_3rvWEvpusuQ3LrMgSbght'

def find_free_port():
    """Dynamically find an available network port"""
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        s.bind(('', 0))
        return s.getsockname()[1]

def preprocess_ppg(signal, fs=100):
    """Preprocess PPG signal using bandpass filter"""
    nyquist = 0.5 * fs
    b, a = butter(3, [0.5/nyquist, 5/nyquist], btype='band')
    return filtfilt(b, a, signal)

def extract_features(signal, fs):
    """Extract features from PPG signal"""
    peaks, _ = find_peaks(signal, height=0.6*np.max(signal))
    return {
        'heart_rate': len(peaks) * (fs / len(signal)) * 60,
        'pulse_amp': np.ptp(signal),
        'dominant_freq': np.argmax(np.abs(fft(signal)))
    }

def initialize_app():
    """Initialize Flask app and model"""
    app = Flask(__name__)

    # ML Model
    mi_classifier = RandomForestClassifier()
    X_train = np.random.rand(100, 3)
    y_train = np.random.randint(0, 2, 100)
    mi_classifier.fit(X_train, y_train)

    # Routes
    @app.route('/')
    def home():
        return jsonify({
            "status": "active",
            "endpoints": {"health_check": "/check_health (POST)"}
        })

    @app.route('/check_health', methods=['POST'])
    def health_check():
        try:
            data = request.json
            if not data or 'user_id' not in data:
                return jsonify({"error": "Invalid request"}), 400

            try:
                ppg_signal = pd.read_csv('/content/copyPPG_Dataset.csv').iloc[0].values
            except FileNotFoundError:
                ppg_signal = np.sin(2 * np.pi * 1 * np.linspace(0, 1, 1000))

            processed = preprocess_ppg(ppg_signal)
            features = extract_features(processed, 100)

            prediction = mi_classifier.predict(pd.DataFrame([features]))[0]

            if prediction == 1 and np.random.rand() > 0.5:
                log_abnormal_signal(data['user_id'])

            return jsonify({
                "status": "MI_risk" if prediction == 1 else "normal",
                "user_id": data['user_id'],
                "features": features
            })

        except Exception as e:
            return jsonify({"error": str(e)}), 500

    return app, mi_classifier

def log_abnormal_signal(user_id):
    """Log abnormal health signals"""
    new_entry = pd.DataFrame([{
        'user_id': user_id,
        'timestamp': datetime.now().isoformat(),
        'lat': 51.505 + np.random.randn()*0.01,
        'lng': -0.09 + np.random.randn()*0.01
    }])
    new_entry.to_csv(DATA_FILE, mode='a', header=False, index=False)

def setup_server():
    """Advanced server setup with robust error handling"""
    # Ensure data file exists
    if not os.path.exists(DATA_FILE):
        pd.DataFrame(columns=['user_id', 'timestamp', 'lat', 'lng']).to_csv(DATA_FILE, index=False)

    # Initialize app and model
    app, _ = initialize_app()
    port = find_free_port()

    try:
        # Start Flask server
        Thread(target=lambda: app.run(
            host=HOST,
            port=port,
            debug=False,
            use_reloader=False
        )).start()

        # Establish ngrok tunnel
        os.environ['NGROK_AUTHTOKEN'] = NGROK_TOKEN
        listener = ngrok.connect(port, authtoken_from_env=True)
        public_url = listener.url()

        print(f"\n{'='*50}")
        print(f"== SERVICE URL: {public_url}")
        print(f"== INTERNAL PORT: {port}")
        print(f"{'='*50}\n")

        return public_url

    except Exception as e:
        print(f"Server startup failed: {e}")
        print(traceback.format_exc())
        raise

def main():
    try:
        server_url = setup_server()
        print(f"Server successfully started at: {server_url}")
    except Exception as startup_error:
        print(f"Critical startup error: {startup_error}")

if __name__ == '__main__':
    main()

"""##Admin view
In real life implementation, AI cameras are used for dataset to train the model. Here sample data is used.
"""

import pandas as pd
import numpy as np
from flask import Flask, jsonify
from flask_ngrok import run_with_ngrok
from IPython.display import HTML
import plotly.graph_objects as go
from sklearn.ensemble import RandomForestRegressor

app = Flask(__name__)
run_with_ngrok(app)

# Traffic Simulation Engine
class DigitalTwin:
    def __init__(self):
        self.road_network = self.load_network()
        self.traffic_model = self.build_traffic_model()
        self.emergency_locations = pd.read_csv('abnormal_signals.csv')

    def load_network(self):
        # Simulated road network data
        return pd.DataFrame({
            'segment_id': [1, 2, 3],
            'capacity': [1000, 1500, 800],
            'current_flow': [650, 1200, 700],
            'coordinates': [
                [[51.505, -0.09], [51.51, -0.085]],
                [[51.51, -0.1], [51.515, -0.095]],
                [[51.515, -0.09], [51.52, -0.085]]
            ]
        })

    def build_traffic_model(self):
        # Traffic prediction model
        model = RandomForestRegressor()
        # model.fit(training_data, labels)  # Add training logic
        return model

    def simulate_scenario(self, event):
        # Simulate traffic impact
        if event['type'] == 'accident':
            affected_segment = self.road_network[self.road_network['segment_id'] == event['segment']]
            new_flow = affected_segment['current_flow'] * 0.3
            self.road_network.loc[affected_segment.index, 'current_flow'] = new_flow

        return self.predict_congestion()

    def predict_congestion(self):
        # Predict congestion using AI model
        return self.traffic_model.predict(self.road_network[['capacity', 'current_flow']])

# Initialize digital twin
digital_twin = DigitalTwin()

@app.route('/traffic_status')
def get_traffic():
    return jsonify(digital_twin.road_network.to_dict(orient='records'))

@app.route('/simulate', methods=['POST'])
def run_simulation():
    scenario = request.json
    results = digital_twin.simulate_scenario(scenario)
    return jsonify({'congestion_levels': results.tolist()})

# Interactive Dashboard
dashboard_html = """
<!DOCTYPE html>
<html>
<head>
    <title>Digital Twin Dashboard</title>
    <link rel="stylesheet" href="https://unpkg.com/leaflet@1.9.4/dist/leaflet.css"/>
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
    <style>
        #map { height: 60vh; }
        #simulationPanel { padding: 20px; background: #f5f5f5; }
        .scenario-btn { margin: 5px; padding: 10px; }
    </style>
</head>
<body>
    <div id="map"></div>
    <div id="simulationPanel">
        <h3>Scenario Simulator</h3>
        <button class="scenario-btn" onclick="runSimulation('accident')">Simulate Accident</button>
        <button class="scenario-btn" onclick="runSimulation('peak')">Simulate Peak Traffic</button>
        <div id="congestionChart"></div>
    </div>

    <script src="https://unpkg.com/leaflet@1.9.4/dist/leaflet.js"></script>
    <script>
        const map = L.map('map').setView([51.505, -0.09], 13);
        L.tileLayer('https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png').addTo(map);

        // Plot emergency signals
        fetch('/traffic_status')
            .then(r => r.json())
            .then(data => {
                data.forEach(segment => {
                    const coordinates = segment.coordinates;
                    L.polyline(coordinates, {color: 'red'}).bindPopup(`
                        Segment ${segment.segment_id}<br>
                        Capacity: ${segment.capacity}<br>
                        Current Flow: ${segment.current_flow}
                    `).addTo(map);
                });
            });

        // Plot abnormal health signals
        fetch('/emergency_locations')
            .then(r => r.json())
            .then(signals => {
                signals.forEach(signal => {
                    L.circleMarker([signal.lat, signal.lng], {
                        radius: 8,
                        color: '#ff0000',
                        fillOpacity: 0.7
                    }).bindPopup(`MI Detected: ${signal.timestamp}`).addTo(map);
                });
            });

        function runSimulation(scenarioType) {
            fetch('/simulate', {
                method: 'POST',
                headers: {'Content-Type': 'application/json'},
                body: JSON.stringify({type: scenarioType, segment: 1})
            })
            .then(r => r.json())
            .then(data => {
                Plotly.newPlot('congestionChart', [{
                    y: data.congestion_levels,
                    type: 'bar',
                    name: 'Congestion Level'
                }], {title: 'Traffic Congestion Prediction'});
            });
        }
    </script>
</body>
</html>
"""

@app.route('/emergency_locations')
def get_emergencies():
    return jsonify(pd.read_csv('abnormal_signals.csv').to_dict(orient='records'))

if __name__ == '__main__':
    display(HTML(dashboard_html))
    app.run()
